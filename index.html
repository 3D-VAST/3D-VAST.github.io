<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3D-VAST: ICCV 2025 Workshop</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/css/bootstrap.min.css">
    <style>
        /* 全局样式 */
        body {
            font-family: 'Segoe UI', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            padding-top: 80px;
        }

        /* 导航栏防遮挡 */
        section::before {
            display: block;
            content: " ";
            margin-top: -80px;
            height: 80px;
            visibility: hidden;
        }

        /* 专业表格样式 */
        .workshop-table {
            border-collapse: collapse;
            width: 100%;
            margin: 25px 0;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }

        .workshop-table th {
            background: #2c3e50;
            color: white;
            padding: 10px;
            text-align: center;
        }

        .workshop-table td {
            padding: 10px;
            border-bottom: 1px solid #ddd;
            text-align: center;
        }

        /* 人员卡片 */
        .profile-card {
            margin: 20px 0;
            padding: 15px;
            border-radius: 8px;
            background: #f8f9fa;
        }

        .profile-img {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            object-fit: cover;
            margin-right: 20px;
        }

        /* 章节标题 */
        .section-title {
            color: #2c3e50;
            border-left: 4px solid #3498db;
            padding-left: 15px;
            margin: 40px 0 30px;
        }

        /* 添加关键信息高亮 */
        .highlight {
            color: #e74c3c;
            font-weight: bold;
        }

        /* 列表样式 */
        ol.workshop-list {
            padding-left: 20px;
        }

        ol.workshop-list li {
            margin-bottom: 10px;
        }

        /* 时间块样式 */
        .time-block {
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 15px;
            background: white;
            margin-bottom: 15px;
        }

        .time {
            color: #3498db;
            font-weight: 600;
            margin-bottom: 8px;
            font-size: 0.9em;
        }

        .event h4 {
            color: #2c3e50;
            margin: 0 0 5px 0;
            font-size: 1.1em;
        }

        /* 茶歇特殊样式 */
        .coffee-break {
            background: #f8f9fa;
            border-color: #3498db;
        }
    </style>
</head>
<body>

<!-- 导航栏 -->
<nav class="navbar navbar-default navbar-fixed-top">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#mainNav">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="#">3D-VAST 2025</a>
        </div>
        <div class="collapse navbar-collapse" id="mainNav">
            <ul class="nav navbar-nav">
                <li><a href="#summary">Summary</a></li>
                <li><a href="#topic">Topic</a></li>
                <li><a href="#organizers">Organizers</a></li>
                <li><a href="#format">Format</a></li>
                <li><a href="#impacts">Impacts</a></li>
                <li><a href="#related">Related Workshops</a></li>
            </ul>
        </div>
    </div>
</nav>

<div class="container">
    <!-- 添加标题 -->
    <h1 style="text-align: center; font-size: 2.5rem; margin: 40px 0; color: #2c3e50;">
        ICCV 2025 Workshop Proposal<br>
        3D-VAST: From street to space: 3D Vision Across Altitudes
    </h1>

    <!-- Summary Section -->
    <section id="summary">
        <h2 class="section-title">1. Summary</h2>
        <table class="workshop-table">
            <tr>
                <th>Workshop Title</th>
                <td>From street to space: <span class="highlight">3D V</span>ision <span class="highlight">A</span>cross<span class="highlight">S</span> aI<span class="highlight">T</span>itudes</td>
            </tr>
            <tr>
                <th>Acronym</th>
                <td>3D-VAST</td>
            </tr>
            <tr>
                <th>Edition</th>
                <td>1st</td>
            </tr>
            <tr>
                <th>Date</th>
                <td>September 29, 2025 (Half-day)</td>
            </tr>
            <tr>
                <th>Keywords</th>
                <td>Cross-altitude data fusion, aerial images, 3D scene modeling</td>
            </tr>
            <tr>
                <th>Primary Contact</th>
                <td>Yujiao Shi &lt;<a href="mailto:shiyj2@shanghaitech.edu.cn">shiyj2@shanghaitech.edu.cn</a>&gt;</td>
            </tr>
            <tr>
                <th>Anticipated Audience</th>
                <td>100 - 300 participants</td>
            </tr>
            <tr>
                <th>Poster Boards Available</th>
                <td>Around 15</td>
            </tr>
            <tr>
                <th>Proceedings</th>
                <td>Papers will be published</td>
            </tr>
        </table>
    </section>

    <!-- Topic Section -->
    <section id="topic">
        <h2 class="section-title">2. Topic</h2>
        <p class="lead">The 3D-VAST workshop focuses on advancing 3D scene modeling through cross-altitude data fusion.</p>
        
        <div class="row">
            <div class="col-md-8">
                <p>As large-scale 3D scene modeling becomes increasingly important for applications such as urban planning, robotics, autonomous navigation, and virtual simulations, the need for diverse, high-quality visual data is greater than ever. However, acquiring dense and high-resolution ground-level imagery at scale is often impractical due to access limitations, cost, and environmental variability. In contrast, aerial and satellite imagery provide broader spatial coverage but lack the fine-grained details needed for many downstream applications. Combining images from multiple altitudes—from ground cameras to aerial drones and satellites—offers a promising solution to overcome these limitations, enabling richer, more complete 3D reconstructions.</p>
                
                <p>How can we achieve coherent and accurate 3D scene modeling when our visual world is captured from vastly different altitudes—ground, aerial, and satellite—under varying conditions? Each altitude offers distinct advantages, but cross-altitude data fusion introduces significant challenges: sparse and incomplete views, visual ambiguities, spatio-temporal inconsistencies, image quality variations, dynamic scene changes, and environmental factors that alter topology over time. Traditional 3D reconstruction methods, optimized for dense and structured inputs, struggle with such heterogeneous multi-altitude data. Advances in multi-scale feature alignment, neural scene representations, and robust cross-view fusion offer promising solutions, but key challenges remain.</p>
                
                <p>3D-VAST invites researchers and practitioners to explore novel techniques in scene modeling, understanding, rendering, and synthesis across altitudes, bridging the gap between ground-level perspectives and large-scale aerial/satellite observations.</p>
            </div>
            <div class="col-md-4">
                <div class="profile-card">
                    <h4>Key Challenges</h4>
                    <ul>
                        <li>Sparse and incomplete views</li>
                        <li>Visual ambiguities</li>
                        <li>Spatio-temporal inconsistencies</li>
                        <li>Image quality variations</li>
                        <li>Dynamic scene changes</li>
                        <li>Environmental topology changes</li>
                    </ul>
                </div>
            </div>
        </div>
        
        <h4>Main Topics</h4>
        <ol class="workshop-table">
            <li>Cross-altitude feature matching and registration</li>
            <li>View synthesis from sparse and heterogeneous data sources</li>
            <li>Sparse-view 3D reconstruction (with known or unknown camera poses)</li>
            <li>Generative approaches for view completion and prediction</li>
            <li>Datasets and benchmarks for evaluating cross-altitude vision systems</li>
            <li>Real-world applications in urban planning, simulation, and digital twins</li>
        </ol>
        
        <h4>Relevance to the Computer Vision Community</h4>
        <p>This workshop aims to tackle fundamental challenges in 3D scene modeling, data fusion, and multi-view geometry across varying altitudes. By focusing on integrating ground-level, aerial, and satellite imagery, the workshop aims to advance cross-altitude feature matching, view synthesis, and neural scene representations, addressing key issues such as spatial inconsistencies, image quality variations, and dynamic scene changes. These topics are critical for the development of robust computer vision algorithms that can handle heterogeneous, multi-source data to achieve accurate, real-time 3D reconstructions.</p>
        
        <h4>Potential ICCV 2025 Attendees</h4>
        <p>The potential attendees of this workshop at ICCV 2025 will include:</p>
        <ul>
            <li>Computer vision researchers working on 3D reconstruction, multi-view geometry, and data fusion</li>
            <li>Experts in robotics, autonomous navigation, and urban planning</li>
            <li>Machine learning practitioners exploring neural scene representations, cross-view feature alignment, and generative approaches for 3D reconstruction</li>
        </ul>
    </section>

<!-- Organizers Section -->
<section id="organizers">
    <h2 class="section-title">3. Organizers & Speakers</h2>
    
    <h4>Organizing Committee</h4>
    
    <div class="row" style="margin: 0 -15px;">
        <!-- 第一行 -->
        <!-- Yujiao Shi -->
        <div class="col-md-4 col-sm-6" style="padding: 0 15px; margin-bottom: 30px;">
            <div class="profile-card">
                <div class="media" style="display: flex; align-items: center;">       
                    <div class="media-left">
                        <img src="pic/Organizers/Yujiao Shi.jpg" class="profile-img">
                    </div>
                    <div class="media-body">
                        <h4><a href="https://yujiaoshi.github.io/" target="_blank">Yujiao Shi</a></h4>
                        <p>Assistant Professor, ShanghaiTech University</p>
                        <p>Research: Camera localization, 3D reconstruction, view synthesis</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Yuanbo Xiangli -->
        <div class="col-md-4 col-sm-6" style="padding: 0 15px; margin-bottom: 30px;">
            <div class="profile-card">
                <div class="media" style="display: flex; align-items: center;">
                    <div class="media-left">
                        <img src="pic/Organizers/ambie.jpg" class="profile-img">
                    </div>
                    <div class="media-body">
                        <h4><a href="https://kam1107.github.io/" target="_blank">Yuanbo Xiangli</a></h4>
                        <p>Postdoctoral Researcher, Cornell University</p>
                        <p>Research: 3D city scene reconstruction with multi-source data</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Zuzana Kukelova -->
        <div class="col-md-4 col-sm-6" style="padding: 0 15px; margin-bottom: 30px;">
            <div class="profile-card">
                <div class="media" style="display: flex; align-items: center;">
                    <div class="media-left">
                        <img src="pic/Organizers/Zuzana Kukelova.jpg" class="profile-img">
                    </div>
                    <div class="media-body">
                        <h4><a href="https://cmp.felk.cvut.cz/~kukelova/" target="_blank">Zuzana Kukelova</a></h4>
                        <p>Assistant Professor, Czech Technical University</p>
                        <p>Research: Camera geometry estimation, minimal problems in CV</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- 第二行 -->
        <!-- Bo Dai -->
        <div class="col-md-4 col-sm-6" style="padding: 0 15px; margin-bottom: 30px;">
            <div class="profile-card">
                <div class="media" style="display: flex; align-items: center;">
                    <div class="media-left">
                        <img src="pic/Organizers/Bo Dai.jpg" class="profile-img">
                    </div>
                    <div class="media-body">
                        <h4><a href="https://datascience.hku.hk/people/bo-dai/" target="_blank">Bo Dai</a></h4>
                        <p>Assistant Professor, The University of Hong Kong</p>
                        <p>Research: Generative AI for Embodied AI and Metaverse</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Richard Hartley -->
        <div class="col-md-4 col-sm-6" style="padding: 0 15px; margin-bottom: 30px;">
            <div class="profile-card">
                <div class="media" style="display: flex; align-items: center;">
                    <div class="media-left">
                        <img src="pic/Organizers/Richard-Hartley.png" class="profile-img">
                    </div>
                    <div class="media-body">
                        <h4><a href="https://comp.anu.edu.au/people/richard-hartley/" target="_blank">Richard Hartley</a></h4>
                        <p>Distinguished Professor Emeritus, ANU</p>
                        <p>Research: Multi-view geometry, scene reconstruction</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Hongdong Li -->
        <div class="col-md-4 col-sm-6" style="padding: 0 15px; margin-bottom: 30px;">
            <div class="profile-card">
                <div class="media" style="display: flex; align-items: center;">
                    <div class="media-left">
                        <img src="pic/Organizers/Hongdong LI.jpg" class="profile-img">
                    </div>
                    <div class="media-body">
                        <h4><a href="https://users.cecs.anu.edu.au/~hongdong/" target="_blank">Hongdong Li</a></h4>
                        <p>Professor, Australian National University</p>
                        <p>Research: 3D vision reconstruction, structure from motion</p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
	
<!-- Invited Speakers -->
<h4 style="margin-top:40px;">Invited Speakers</h4>
	
<!-- Torsten Sattler -->
<div class="profile-card">
	<div class="media">
		<div class="media-left">
			<img src="pic/speakers/Torsten.jpg" class="profile-img">
		</div>
		<div class="media-body">
			<h4><a href="https://tsattler.github.io//" target="_blank">Torsten Sattler</a></h4>
			<p><strong>Affiliation:</strong> Senior Researcher, Czech Technical University <strong>Location:</strong> Europe</p>
			<p><strong>Expertise:</strong> Robust 3D reconstruction and visual localization <strong>Experience:</strong> Program Chair for DAGM GCPR'20, 3DV'22 General Chair</p>
			<p><strong>Profile:</strong> Torsten Sattler is a Senior Researcher at CTU, where he heads the Spatial Intelligence group. His work is in the intersection of 3D computer vision and machine learning, with the goal of making 3D computer vision algorithms such as 3D reconstruction and visual localization more robust and reliable through scene understanding. Torsten has (co-)organized tutorials and workshops on visual localization at the main computer vision conference.</p>
		</div>
	</div>
</div>

<!-- Angela Dai -->
<div class="profile-card">
	<div class="media">
		<div class="media-left">
			<img src="pic/speakers/Dai.jpg" class="profile-img">
		</div>
		<div class="media-body">
			<h4><a href="https://www.professoren.tum.de/en/dai-angela" target="_blank">Angela Dai</a></h4>
			<p><strong>Affiliation:</strong> Associate Professor, Technical University of Munich <strong>Location:</strong> Europe</p>
			<p><strong>Expertise:</strong> 3D scene understanding and modeling <strong>Awards:</strong> ERC Starting Grant, Eurographics Young Researcher Award</p>
			<p><strong>Profile:</strong> Angela Dai is an Associate Professor at Technical University of Munich, where she leads the 3D AI group. Her research focuses on understanding how the 3D world can be modeled. Her research has been recognized through various prestigious awards, including the ERC Starting Grant, Eurographics Young Researcher Award, Google Research Scholar Award, and ZDB Junior Research Group Award.</p>
		</div>
	</div>
</div>

<!-- Noah Snavely -->
<div class="profile-card">
	<div class="media">
		<div class="media-left">
			<img src="pic/speakers/Noah.jpg" class="profile-img">
		</div>
		<div class="media-body">
			<h4><a href="https://www.cs.cornell.edu/~snavely/" target="_blank">Noah Snavely</a></h4>
			<p><strong>Affiliation:</strong> Professor, Cornell Tech & Google DeepMind <strong>Location:</strong> The United States</p>
			<p><strong>Expertise:</strong> 3D scene understanding from images <strong>Awards:</strong> Sloan Fellowship, SIGGRAPH Significant New Researcher Award</p>
			<p><strong>Profile:</strong> Noah Snavely is a Professor of Computer Science at Cornell Tech interested. He also works at Google DeepMind in NYC. His research interests are in computer vision and graphics, in particular in 3D understanding and depiction of scenes from images. Noah is the recipient of numerous prestigious awards, including a PECASE, a Microsoft New Faculty Fellowship, an Alfred P. Sloan Fellowship, and a SIGGRAPH Significant New Researcher Award.</p>
		</div>
	</div>
</div>

<!-- Nathan Jacobs -->
<div class="profile-card">
	<div class="media">
		<div class="media-left">
			<img src="pic/speakers/nathan.jpg" class="profile-img">
		</div>
		<div class="media-body">
			<h4><a href="https://jacobsn.github.io/" target="_blank">Nathan Jacobs</a></h4>
			<p><strong>Affiliation:</strong> Professor, Washington University in St. Louis <strong>Location:</strong> The United States</p>
			<p><strong>Expertise:</strong> Geospatial analysis from crowdsourced imagery <strong>Funding:</strong> NSF, NIH, DARPA, IARPA, etc.</p>
			<p><strong>Profile:</strong> Nathan Jacobs is a Professor at Washington University in St. Louis. His current focus is developing techniques for mining information about the natural world from geotagged imagery, including images from social networks, publicly available outdoor webcams, and satellites. His research has been funded by numerous prestigious organizations, including NSF, NIH, DARPA, IARPA, NGA, ARL, AFRL, and Google.</p>
		</div>
	</div>
</div>

<!-- Jingyi Yu -->
<div class="profile-card">
	<div class="media">
		<div class="media-left">
			<img src="pic/speakers/jingyi yu.jpg" class="profile-img">
		</div>
		<div class="media-body">
			<h4><a href="https://sist.shanghaitech.edu.cn/yujingyi_en/main.htm" target="_blank">Jingyi Yu</a></h4>
			<p><strong>Affiliation:</strong> Chair Professor, ShanghaiTech University <strong>Location:</strong> Asia</p>
			<p><strong>Expertise:</strong> Computational photography and camera design <strong>Awards:</strong> NSF CAREER Award, AFOSR YIP Award</p>
			<p><strong>Profile:</strong> Jingyi Yu is a Chair Professor and the Vice Provost of ShanghaiTech University. He also serves as the Dean of the School of Information Science and Technology at ShanghaiTech University. His research interests span a range of topics in computer vision and computer graphics, especially on computational photography and non-conventional optics and camera designs. He is a recipient of the NSF CAREER Award, the AFOSR YIP Award, and the Outstanding Junior Faculty Award at the University of Delaware.</p>
		</div>
	</div>
</div>
	
       <!-- Schedule Section -->
       <section id="format">
       <h2 class="section-title">4. Format and logistics</h2>
        <h4 class="text-center">Workshop Schedule</h4>
    
        <div class="schedule-container">
            <!-- 早晨时段 -->
            <div class="time-slot morning">
                <div class="time-block">
                    <div class="time">08:30 - 08:35</div>
                    <div class="event">
                        <h4>Workshop Kickoff&Opening Comments</h4>
                    </div>
                </div>
                <div class="time-block">
                    <div class="time">08:35 - 09:05</div>
                    <div class="event">
                        <h4>Keynote Speech I</h4>
                    </div>
                </div>
                <div class="time-block">
                    <div class="time">09:05 - 09:35</div>
                    <div class="event">
                        <h4>Keynote Speech II</h4>
                    </div>
                </div>
                <div class="time-block">
                    <div class="time">09:35 - 10:05</div>
                    <div class="event">
                        <h4>Keynote Speech III</h4>
                    </div>
                </div>
            </div>

            <!-- 茶歇 -->
            <div class="time-slot break">
                <div class="time-block full-width">
                    <div class="time">10:05 - 11:00</div>
                    <div class="event">
                        <h4>Coffee Break & Poster Session</h4>
                    </div>
                </div>
            </div>

            <!-- 下午时段 -->
            <div class="time-slot afternoon">
                <div class="time-block">
                    <div class="time">11:00 - 11:30</div>
                    <div class="event">
                        <h4>Keynote Speech IV</h4>
                    </div>
                </div>
                <div class="time-block">
                    <div class="time">11:30 - 12:00</div>
                    <div class="event">
                        <h4>Keynote Speech V</h4>
                    </div>
                </div>
            </div>
        </div>

        <style>
            .schedule-container {
                max-width: 800px;
                margin: 0 auto;
                padding: 20px;
            }

            .time-slot {
                display: grid;
                grid-template-columns: repeat(2, 1fr);
                gap: 15px;
                margin-bottom: 15px;
            }

            .time-block {
                border: 1px solid #e0e0e0;
                border-radius: 8px;
                padding: 15px;
                background: white;
                transition: transform 0.2s;
            }

            .time-block:hover {
                transform: translateY(-3px);
                box-shadow: 0 3px 10px rgba(0,0,0,0.1);
            }

            .time {
                color: #3498db;
                font-weight: 600;
                margin-bottom: 8px;
                font-size: 0.9em;
            }

            .event h4 {
                color: #2c3e50;
                margin: 0 0 5px 0;
                font-size: 1.1em;
            }

            .event p {
                color: #7f8c8d;
                margin: 0;
                font-size: 0.9em;
            }

            /* 茶歇特殊样式 */
            .break .time-block {
                grid-column: 1 / -1;
                background: #f8f9fa;
                border-color: #3498db;
            }

            .break h4 {
                color: #3498db;
            }

            /* 响应式设计 */
            @media (max-width: 768px) {
                .time-slot {
                    grid-template-columns: 1fr;
                }
            
                .time-block {
                    padding: 12px;
                }
            
                .event h4 {
                    font-size: 1em;
                }
            }
        </style>
    </section>
    
    <!-- Impacts Section -->
    <section id="impacts">
        <h2 class="section-title">5. Broader Impacts</h2>
        <div class="panel panel-default">
            <div class="panel-body">
                <h4>Applications</h4>
                <ul>
                    <li>Urban planning and smart cities</li>
                    <li>Autonomous navigation systems</li>
                    <li>Digital twin development</li>
                </ul>

                <h4>Ethical Considerations</h4>
                <ul>
                    <li>Privacy protection in multi-altitude data</li>
                    <li>Algorithmic bias mitigation</li>
                    <li>Surveillance ethics</li>
                </ul>
            </div>
        </div>
    </section>

<!-- Related Workshops Section -->
<section id="related">
    <h2 class="section-title">Related Workshops</h2>
    
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <div class="card">
                    <div class="card-body">
                        <h5 class="card-title">Our Workshop</h5>
                        <p class="card-text">
                            Our workshop aims to address key challenges in 3D scene understanding, modeling, and data fusion across multiple altitudes, integrating both ground-level and aerial perspectives.
                        </p>
                    </div>
                </div>
            </div>
        </div>

        <div class="row mt-4">
            <div class="col-md-6">
                <div class="card border-info">
                    <div class="card-body">
                        <h5 class="card-title">EarthVision (CVPR 2021-2024)</h5>
                        <p class="card-text">
                            Focuses on satellite imagery only for large-scale environmental monitoring.
                        </p>
                    </div>
                </div>
            </div>
            <div class="col-md-6">
                <div class="card border-primary">
                    <div class="card-body">
                        <h5 class="card-title">Scalable 3D Scene Generation (ECCV 2024)</h5>
                        <p class="card-text">
                            Emphasizes large-scale 3D scene generation.
                        </p>
                    </div>
                </div>
            </div>
        </div>

        <div class="row mt-4">
            <div class="col-md-12">
                <div class="card">
                    <div class="card-body">
                        <h5 class="card-title">Our Unique Approach</h5>
                        <p class="card-text">
                            Unlike EarthVision and the ECCV 2024 workshop, our workshop explores the collaboration across multiple altitude data sources to enhance scene modeling and understanding. Specifically, we emphasize how drone-based aerial and satellite data can complement ground-level data to achieve a more complete and accurate understanding of the world and its 3D modeling.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<footer class="text-center mt-5 py-4 border-top">
    <p class="mb-1">© 2025 3D-VAST Workshop Committee</p>
    <p>Contact: <a href="mailto:shiyj2@shanghaitech.edu.cn" class="text-reset text-decoration-none">shiyj2@shanghaitech.edu.cn</a></p>
</footer>

<!-- Scripts -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.bundle.min.js"></script>
