<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3D-VAST: ICCV 2025 Workshop</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/css/bootstrap.min.css">
    <style>
        /* 全局样式 */
        body {
            font-family: 'Segoe UI', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            padding-top: 80px;
        }

        /* 导航栏防遮挡 */
        section::before {
            display: block;
            content: " ";
            margin-top: -80px;
            height: 80px;
            visibility: hidden;
        }

        /* 专业表格样式 */
        .workshop-table {
            border-collapse: collapse;
            width: 100%;
            margin: 25px 0;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }

        .workshop-table th {
            background: #2c3e50;
            color: white;
            padding: 10px;
            text-align: center;
        }

        .workshop-table td {
            padding: 10px;
            border-bottom: 1px solid #ddd;
            text-align: center;
        }

        /* 人员卡片 */
        .profile-card {
            margin: 20px 0;
            padding: 15px;
            border-radius: 8px;
            background: #f8f9fa;
        }

        .profile-img {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            object-fit: cover;
            margin-right: 20px;
        }

        /* 章节标题 */
        .section-title {
            color: #2c3e50;
            border-left: 4px solid #3498db;
            padding-left: 15px;
            margin: 40px 0 30px;
        }

        /* 添加关键信息高亮 */
        .highlight {
            color: #e74c3c;
            font-weight: bold;
        }

        /* 列表样式 */
        ol.workshop-list {
            padding-left: 20px;
        }

        ol.workshop-list li {
            margin-bottom: 10px;
        }

        /* 时间块样式 */
        .time-block {
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 15px;
            background: white;
            margin-bottom: 15px;
        }

        .time {
            color: #3498db;
            font-weight: 600;
            margin-bottom: 8px;
            font-size: 0.9em;
        }

        .event h4 {
            color: #2c3e50;
            margin: 0 0 5px 0;
            font-size: 1.1em;
        }

        /* 茶歇特殊样式 */
        .coffee-break {
            background: #f8f9fa;
            border-color: #3498db;
        }
    </style>
</head>
<body>

<!-- 导航栏 -->
<nav class="navbar navbar-default navbar-fixed-top">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#mainNav">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="#">3D-VAST 2025</a>
        </div>
        <div class="collapse navbar-collapse" id="mainNav">
            <ul class="nav navbar-nav">
                <li><a href="#summary">Summary</a></li>
                <li><a href="#topic">Topic</a></li>
                <li><a href="#organizers">Organizers</a></li>
                <li><a href="#format">Format</a></li>
                <li><a href="#impacts">Impacts</a></li>
                <li><a href="#related">Related Workshops</a></li>
            </ul>
        </div>
    </div>
</nav>

<div class="container">
    <!-- 添加标题 -->
    <h1 style="text-align: center; font-size: 2.5rem; margin: 40px 0; color: #2c3e50;">
        ICCV 2025 Workshop Proposal<br>
        3D-VAST: From street to space: 3D Vision Across Altitudes
    </h1>

  <!-- Summary Section -->
<section id="summary">
    <h2 class="section-title">1. Summary</h2>
    <table class="workshop-table">
        <tr>
            <th>Workshop Title</th>
            <td>From street to space: <span class="highlight">3D V</span>ision <span class="highlight">A</span>cross<span class="highlight">S</span> aI<span class="highlight">T</span>itudes</td>
        </tr>
        <tr>
            <th>Acronym</th>
            <td>3D-VAST</td>
        </tr>
        <tr>
            <th>Edition</th>
            <td>1st</td>
        </tr>
        <tr>
            <th>Half or full day</th>
            <td>Half Day</td>
        </tr>
        <tr>
            <th>Keywords</th>
            <td>Cross-altitude data fusion, aerial images, 3D scene modeling</td>
        </tr>
        <tr>
            <th>Primary Contact</th>
            <td>Yujiao Shi &lt;<a href="mailto:shiyj2@shanghaitech.edu.cn">shiyj2@shanghaitech.edu.cn</a>&gt;</td>
        </tr>
        <tr>
            <th>Anticipated Audience</th>
            <td>100 - 300 participants</td>
        </tr>
        <tr>
            <th>Poster Boards Available</th>
            <td>Around 15</td>
        </tr>
        <tr>
            <th>Proceedings</th>
            <td>Papers will be published</td>
        </tr>
        <!-- 添加论文提交相关的时间节点 -->
        <tr>
            <th style="width: 30%">Paper Submission Deadline</th>
            <td>July 5 '25 (One week after the ICCV notification time)</td>
        </tr>
        <tr>
            <th>Camera Ready Deadline</th>
            <td>October 21 - 23 '25 (Consistent with the ICCV conference time)</td>
        </tr>
    </table>
</section>
	
<!-- Topic Section -->
<section id="topic" class="py-5">
    <h2 class="section-title mb-4">2. Topic</h2>
    <p class="lead fw-bold">Bridging Multi-Altitude Vision for Scalable 3D Scene Understanding</p>
    
    <div class="row g-4">
        <div class="col-lg-8">
            <div class="card shadow-sm">
                <div class="card-body">
                    <h4 class="card-title mb-3">Workshop Motivation</h4>
                    <p class="card-text">While modern 3D modeling plays a pivotal role in urban planning, autonomous systems, and digital twin creation, current approaches face fundamental limitations:</p>
                    
                    <div class="alert alert-light bg-light border">
                        <ul class="mb-0">
                            <li>Ground-level capture suffers from <strong>spatial fragmentation</strong> and <strong>environmental constraints</strong></li>
                            <li>Aerial/satellite systems offer <strong>broad coverage</strong> but lack <strong>actionable granularity</strong></li>
                            <li>Existing fusion methods struggle with <strong>multi-scale alignment</strong> and <strong>temporal variance</strong></li>
                        </ul>
                    </div>

                    <p class="card-text">This workshop addresses the critical need for unified frameworks that reconcile <strong>ground-level fidelity</strong> with <strong>aerial context</strong>, enabling holistic scene understanding across spatial scales. Key technical hurdles include resolving geometric discontinuities between perspectives and overcoming temporal misalignment in dynamic environments.</p>
                </div>
            </div>
        </div>

        <div class="col-lg-4">
            <div class="card shadow-sm h-100">
                <div class="card-body">
                    <h4 class="card-title mb-3">Core Technical Challenges</h4>
                    <div class="list-group list-group-flush">
                        <div class="list-group-item d-flex align-items-center">
                            <i class="bi bi-camera-fill me-3 text-primary"></i>
                            <span>Multi-altitude feature correspondence</span>
                        </div>
                        <div class="list-group-item d-flex align-items-center">
                            <i class="bi bi-stack me-3 text-primary"></i>
                            <span>Neural field integration across scales</span>
                        </div>
                        <div class="list-group-item d-flex align-items-center">
                            <i class="bi bi-clock-history me-3 text-primary"></i>
                            <span>Temporal synchronization of dynamic scenes</span>
                        </div>
                        <div class="list-group-item d-flex align-items-center">
                            <i class="bi bi-gpu-card me-3 text-primary"></i>
                            <span>Cross-modal quality normalization</span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <div class="row mt-4 g-4">
        <div class="col-md-6">
            <div class="card shadow-sm">
                <div class="card-body">
                    <h4 class="card-title mb-3">Technical Scope</h4>
                    <ol class="list-group list-group-numbered">
                        <li class="list-group-item d-flex align-items-start">
                            <span class="me-auto">Cross-altitude feature matching & neural registration</span>
                        </li>
                        <li class="list-group-item d-flex align-items-start">
                            <span class="me-auto">Multi-source view synthesis with uncertainty modeling</span>
                        </li>
                        <li class="list-group-item d-flex align-items-start">
                            <span class="me-auto">Pose-aware & blind sparse reconstruction</span>
                        </li>
                        <li class="list-group-item d-flex align-items-start">
                            <span class="me-auto">Differentiable rendering for cross-altitude completion</span>
                        </li>
                        <li class="list-group-item d-flex align-items-start">
                            <span class="me-auto">Benchmarking cross-altitude perception systems</span>
                        </li>
                    </ol>
                </div>
            </div>
        </div>

        <div class="col-md-6">
            <div class="card shadow-sm h-100">
                <div class="card-body">
                    <h4 class="card-title mb-3">Impact & Applications</h4>
                    <div class="row row-cols-2 g-3">
                        <div class="col">
                            <div class="card bg-light h-100">
                                <div class="card-body">
                                    <h6 class="card-subtitle mb-2 text-muted">Urban Intelligence</h6>
                                    <p class="card-text small">Dynamic 3D city models for infrastructure monitoring</p>
                                </div>
                            </div>
                        </div>
                        <div class="col">
                            <div class="card bg-light h-100">
                                <div class="card-body">
                                    <h6 class="card-subtitle mb-2 text-muted">Autonomous Systems</h6>
                                    <p class="card-text small">Multi-scale navigation graphs for robotics</p>
                                </div>
                            </div>
                        </div>
                        <div class="col">
                            <div class="card bg-light h-100">
                                <div class="card-body">
                                    <h6 class="card-subtitle mb-2 text-muted">Virtualization</h6>
                                    <p class="card-text small">Physics-aware digital twin simulation</p>
                                </div>
                            </div>
                        </div>
                        <div class="col">
                            <div class="card bg-light h-100">
                                <div class="card-body">
                                    <h6 class="card-subtitle mb-2 text-muted">Geospatial AI</h6>
                                    <p class="card-text small">Temporal 3D mapping for climate analysis</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
	
<section id="organizers">
    <h2 class="section-title">3. Organizers & Speakers</h2>
    
    <h4>Organizing Committee</h4>
    
    <!-- 第一行 -->
    <div class="row mb-4">
        <!-- Yujiao Shi -->
        <div class="col-md-4">
            <div class="profile-card">
                <div class="media" style="display: flex; align-items: center;">       
                    <div class="media-left">
                        <img src="pic/Organizers/Yujiao Shi.jpg" class="profile-img">
                    </div>
                    <div class="media-body">
                        <h4><a href="https://yujiaoshi.github.io/" target="_blank">Yujiao Shi</a></h4>
                        <p>Assistant Professor, ShanghaiTech University</p>
                        <p>Research: Camera localization, 3D reconstruction, view synthesis</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Yuanbo Xiangli -->
        <div class="col-md-4">
            <div class="profile-card">
                <div class="media" style="display: flex; align-items: center;">
                    <div class="media-left">
                        <img src="pic/Organizers/ambie.jpg" class="profile-img">
                    </div>
                    <div class="media-body">
                        <h4><a href="https://kam1107.github.io/" target="_blank">Yuanbo Xiangli</a></h4>
                        <p>Postdoctoral Researcher, Cornell University</p>
                        <p>Research: 3D city scene reconstruction with multi-source data</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Zuzana Kukelova -->
        <div class="col-md-4">
            <div class="profile-card">
                <div class="media" style="display: flex; align-items: center;">
                    <div class="media-left">
                        <img src="pic/Organizers/Zuzana Kukelova.jpg" class="profile-img">
                    </div>
                    <div class="media-body">
                        <h4><a href="https://cmp.felk.cvut.cz/~kukelova/" target="_blank">Zuzana Kukelova</a></h4>
                        <p>Assistant Professor, Czech Technical University</p>
                        <p>Research: Camera geometry estimation, minimal problems in CV</p>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- 第二行 -->
    <div class="row">
        <!-- Bo Dai -->
        <div class="col-md-4">
            <div class="profile-card">
                <div class="media" style="display: flex; align-items: center;">
                    <div class="media-left">
                        <img src="pic/Organizers/Bo Dai.jpg" class="profile-img">
                    </div>
                    <div class="media-body">
                        <h4><a href="https://datascience.hku.hk/people/bo-dai/" target="_blank">Bo Dai</a></h4>
                        <p>Assistant Professor, The University of Hong Kong</p>
                        <p>Research: Generative AI for Embodied AI and Metaverse</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Richard Hartley -->
        <div class="col-md-4">
            <div class="profile-card">
                <div class="media" style="display: flex; align-items: center;">
                    <div class="media-left">
                        <img src="pic/Organizers/Richard-Hartley.png" class="profile-img">
                    </div>
                    <div class="media-body">
                        <h4><a href="https://comp.anu.edu.au/people/richard-hartley/" target="_blank">Richard Hartley</a></h4>
                        <p>Distinguished Professor Emeritus, ANU</p>
                        <p>Research: Multi-view geometry, scene reconstruction</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Hongdong Li -->
        <div class="col-md-4">
            <div class="profile-card">
                <div class="media" style="display: flex; align-items: center;">
                    <div class="media-left">
                        <img src="pic/Organizers/Hongdong LI.jpg" class="profile-img">
                    </div>
                    <div class="media-body">
                        <h4><a href="https://users.cecs.anu.edu.au/~hongdong/" target="_blank">Hongdong Li</a></h4>
                        <p>Professor, Australian National University</p>
                        <p>Research: 3D vision reconstruction, structure from motion</p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

	
<!-- Invited Speakers Section -->
<h4 style="margin-top:40px;">Invited Speakers</h4>

<style>
.info-row {
    display: flex;
    justify-content: space-between;
    margin-bottom: 10px;
}
.profile-card p {
    margin: 0;
}
.profile-card p:first-of-type {
    margin-top: 0;
}
.profile-card p:last-of-type {
    margin-bottom: 10px;
}
.profile-card h4 {
    margin-top: 0;
}
</style>

<!-- Torsten Sattler -->
<div class="profile-card">
    <div class="media">
        <div class="media-left">
            <img src="pic/speakers/Torsten.jpg" class="profile-img">
        </div>
        <div class="media-body">
            <h4><a href="https://tsattler.github.io/" target="_blank">Torsten Sattler</a></h4>
            <div class="info-row">
                <p><strong>Affiliation:</strong> Senior Researcher, Czech Technical University</p>
                <p><strong>Location:</strong> Europe</p>
            </div>
            <div class="info-row">
                <p><strong>Expertise:</strong> Robust 3D reconstruction and visual localization</p>
                <p><strong>Experience:</strong> Program Chair for DAGM GCPR'20, 3DV'22 General Chair</p>
            </div>
            <p><strong>Profile:</strong> Torsten Sattler is a Senior Researcher at CTU, where he heads the Spatial Intelligence group. His work is in the intersection of 3D computer vision and machine learning, with the goal of making 3D computer vision algorithms such as 3D reconstruction and visual localization more robust and reliable through scene understanding. Torsten has (co-)organized tutorials and workshops on visual localization at the main computer vision conference.</p>
        </div>
    </div>
</div>

<!-- Angela Dai -->
<div class="profile-card">
    <div class="media">
        <div class="media-left">
            <img src="pic/speakers/Dai.jpg" class="profile-img">
        </div>
        <div class="media-body">
            <h4><a href="https://www.professoren.tum.de/en/dai-angela" target="_blank">Angela Dai</a></h4>
            <div class="info-row">
                <p><strong>Affiliation:</strong> Associate Professor, Technical University of Munich</p>
                <p><strong>Location:</strong> Europe</p>
            </div>
            <div class="info-row">
                <p><strong>Expertise:</strong> 3D scene understanding and modeling</p>
                <p><strong>Awards:</strong> ERC Starting Grant, Eurographics Young Researcher Award</p>
            </div>
            <p><strong>Profile:</strong> Angela Dai is an Associate Professor at Technical University of Munich, where she leads the 3D AI group. Her research focuses on understanding how the 3D world can be modeled. Her research has been recognized through various prestigious awards, including the ERC Starting Grant, Eurographics Young Researcher Award, Google Research Scholar Award, and ZDB Junior Research Group Award.</p>
        </div>
    </div>
</div>

<!-- Noah Snavely -->
<div class="profile-card">
    <div class="media">
        <div class="media-left">
            <img src="pic/speakers/Noah.jpg" class="profile-img">
        </div>
        <div class="media-body">
            <h4><a href="https://www.cs.cornell.edu/~snavely/" target="_blank">Noah Snavely</a></h4>
            <div class="info-row">
                <p><strong>Affiliation:</strong> Professor, Cornell Tech & Google DeepMind</p>
                <p><strong>Location:</strong> The United States</p>
            </div>
            <div class="info-row">
                <p><strong>Expertise:</strong> 3D scene understanding from images</p>
                <p><strong>Awards:</strong> Sloan Fellowship, SIGGRAPH Significant New Researcher Award</p>
            </div>
            <p><strong>Profile:</strong> Noah Snavely is a Professor of Computer Science at Cornell Tech interested. He also works at Google DeepMind in NYC. His research interests are in computer vision and graphics, in particular in 3D understanding and depiction of scenes from images. Noah is the recipient of numerous prestigious awards, including a PECASE, a Microsoft New Faculty Fellowship, an Alfred P. Sloan Fellowship, and a SIGGRAPH Significant New Researcher Award.</p>
        </div>
    </div>
</div>

<!-- Nathan Jacobs -->
<div class="profile-card">
    <div class="media">
        <div class="media-left">
            <img src="pic/speakers/nathan.jpg" class="profile-img">
        </div>
        <div class="media-body">
            <h4><a href="https://jacobsn.github.io/" target="_blank">Nathan Jacobs</a></h4>
            <div class="info-row">
                <p><strong>Affiliation:</strong> Professor, Washington University in St. Louis</p>
                <p><strong>Location:</strong> The United States</p>
            </div>
            <div class="info-row">
                <p><strong>Expertise:</strong> Geospatial analysis from crowdsourced imagery</p>
                <p><strong>Funding:</strong> NSF, NIH, DARPA, IARPA, etc.</p>
            </div>
            <p><strong>Profile:</strong> Nathan Jacobs is a Professor at Washington University in St. Louis. His current focus is developing techniques for mining information about the natural world from geotagged imagery, including images from social networks, publicly available outdoor webcams, and satellites. His research has been funded by numerous prestigious organizations, including NSF, NIH, DARPA, IARPA, NGA, ARL, AFRL, and Google.</p>
        </div>
    </div>
</div>

<!-- Jingyi Yu -->
<div class="profile-card">
    <div class="media">
        <div class="media-left">
            <img src="pic/speakers/jingyi yu.jpg" class="profile-img">
        </div>
        <div class="media-body">
            <h4><a href="https://sist.shanghaitech.edu.cn/yujingyi_en/main.htm" target="_blank">Jingyi Yu</a></h4>
            <div class="info-row">
                <p><strong>Affiliation:</strong> Chair Professor, ShanghaiTech University</p>
                <p><strong>Location:</strong> Asia</p>
            </div>
            <div class="info-row">
                <p><strong>Expertise:</strong> Computational photography and camera design</p>
                <p><strong>Awards:</strong> NSF CAREER Award, AFOSR YIP Award</p>
            </div>
            <p><strong>Profile:</strong> Jingyi Yu is a Chair Professor and the Vice Provost of ShanghaiTech University. He also serves as the Dean of the School of Information Science and Technology at ShanghaiTech University. His research interests span a range of topics in computer vision and computer graphics, especially on computational photography and non-conventional optics and camera designs. He is a recipient of the NSF CAREER Award, the AFOSR YIP Award, and the Outstanding Junior Faculty Award at the University of Delaware.</p>
        </div>
    </div>
</div>

<!-- Diversity -->
	    <div class="card mb-4">
        <div class="card-header">
            <h3 class="card-title">Diversity</h3>
        </div>
        <div class="card-body">
            <p class="card-text"><strong>Organizers:</strong>strong> (1) <strong>Gender balance:</strong>strong> The team comprises three female and three male researchers, promoting gender inclusivity. (2) <strong>Different career stages:</strong>strong> The committee includes two full professors, three assistant professors, and one postdoctoral researcher, representing a range of academic experiences and perspectives. (3) <strong>Geographical diversity:</strong>strong> The organizers are affiliated with institutions across the globe, including Europe, America, Hong Kong, mainland China, and Australia, ensuring a broad representation of regional viewpoints and expertise.</p>
	    <p class="card-text">The confirmed speakers include (1) <strong>one female and four males</strong>strong>, representing a wide range of research interests that align closely with the workshop’s theme. (2) <strong>Their expertise spans</strong>strong> street level 3D reconstruction (e.g., urban scene understanding and ground-level visual localization), aerial vision systems (e.g., drone-based mapping and environmental monitoring), and satellite-based vision (e.g., large-scale geospatial analysis). This <strong>ensures comprehensive coverage of the workshop’s focus.</strong>strong> (3) <strong>Geographically</strong>strong>, the speakers are affiliated with leading institutions across Europe (e.g., Technical University of Munich, Czech Technical University in Prague), the United States (e.g., Cornell Tech, Washington University in St. Louis), and Asia (e.g., ShanghaiTech University), fostering a truly global exchange of ideas and collaboration.</p>
	</div>
    </div>
       <!-- Schedule Section -->
       <section id="format">
       <h2 class="section-title">4. Format and logistics</h2>
        <h4 class="text-center">Workshop Schedule</h4>
    
        <div class="schedule-container">
            <!-- 早晨时段 -->
            <div class="time-slot morning">
                <div class="time-block">
                    <div class="time">08:30 - 08:35</div>
                    <div class="event">
                        <h4>Workshop Kickoff&Opening Comments</h4>
                    </div>
                </div>
                <div class="time-block">
                    <div class="time">08:35 - 09:05</div>
                    <div class="event">
                        <h4>Keynote Speech I</h4>
                    </div>
                </div>
                <div class="time-block">
                    <div class="time">09:05 - 09:35</div>
                    <div class="event">
                        <h4>Keynote Speech II</h4>
                    </div>
                </div>
                <div class="time-block">
                    <div class="time">09:35 - 10:05</div>
                    <div class="event">
                        <h4>Keynote Speech III</h4>
                    </div>
                </div>
            </div>

            <!-- 茶歇 -->
            <div class="time-slot break">
                <div class="time-block full-width">
                    <div class="time">10:05 - 11:00</div>
                    <div class="event">
                        <h4>Coffee Break & Poster Session</h4>
                    </div>
                </div>
            </div>

            <!-- 下午时段 -->
            <div class="time-slot afternoon">
                <div class="time-block">
                    <div class="time">11:00 - 11:30</div>
                    <div class="event">
                        <h4>Keynote Speech IV</h4>
                    </div>
                </div>
                <div class="time-block">
                    <div class="time">11:30 - 12:00</div>
                    <div class="event">
                        <h4>Keynote Speech V</h4>
                    </div>
                </div>
            </div>
        </div>

        <style>
            .schedule-container {
                max-width: 800px;
                margin: 0 auto;
                padding: 20px;
            }

            .time-slot {
                display: grid;
                grid-template-columns: repeat(2, 1fr);
                gap: 15px;
                margin-bottom: 15px;
            }

            .time-block {
                border: 1px solid #e0e0e0;
                border-radius: 8px;
                padding: 15px;
                background: white;
                transition: transform 0.2s;
            }

            .time-block:hover {
                transform: translateY(-3px);
                box-shadow: 0 3px 10px rgba(0,0,0,0.1);
            }

            .time {
                color: #3498db;
                font-weight: 600;
                margin-bottom: 8px;
                font-size: 0.9em;
            }

            .event h4 {
                color: #2c3e50;
                margin: 0 0 5px 0;
                font-size: 1.1em;
            }

            .event p {
                color: #7f8c8d;
                margin: 0;
                font-size: 0.9em;
            }

            /* 茶歇特殊样式 */
            .break .time-block {
                grid-column: 1 / -1;
                background: #f8f9fa;
                border-color: #3498db;
            }

            .break h4 {
                color: #3498db;
            }

            /* 响应式设计 */
            @media (max-width: 768px) {
                .time-slot {
                    grid-template-columns: 1fr;
                }
            
                .time-block {
                    padding: 12px;
                }
            
                .event h4 {
                    font-size: 1em;
                }
            }
        </style>
    </section>
    
<!-- Impacts Section -->
<section id="impacts">
  <h2 class="section-title">Impacts Section</h2>

    <div class="card mb-4">
        <div class="card-header">
            <h3 class="card-title">Social Considerations</h3>
        </div>
        <div class="card-body">
            <p class="card-text">The workshop raises social considerations about privacy and data security. The use of ground, aerial, and satellite data often involves personal and community-level information. It is crucial to ensure equitable access to these technologies to prevent the deepening of social disparities.</p>
            <p class="card-text">The workshop will highlight the need for inclusive solutions that promote fairness and community trust while ensuring that these technologies benefit all sections of society.</p>
        </div>
    </div>
    
    <div class="card">
        <div class="card-header">
            <h3 class="card-title">Ethical Considerations</h3>
        </div>
        <div class="card-body">
            <p class="card-text">Developing technologies that rely on multi-source data fusion raises concerns such as the misuse of data for surveillance purposes, where aerial and satellite imagery could be used to track individuals or monitor private spaces without consent.</p>
            <p class="card-text">Moreover, ensuring that the algorithms and models used are free from biases is critical to avoid discriminatory outcomes. The workshop will explore how to design these systems with a focus on transparency, accountability, and fairness, ensuring that technological advancements are ethically sound and serve the greater good.</p>
        </div>
    </div>
</section>

<!-- Related Workshops Section -->
<section id="related">
    <h2 class="section-title">Related Workshops</h2>
    
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <div class="card">
                    <div class="card-body">
                        <h5 class="card-title">Our Workshop</h5>
                        <p class="card-text">
                            This workshop aims to address key challenges in 3D scene understanding, modeling, and data fusion across multiple altitudes, integrating both ground-level and aerial perspectives. While it sharessimilarities with workshops such as EarthVision: Large Scale Computer Vision for Remote Sensing Imagery (CVPR 2021-2024) and Scalable 3D Scene Generation and Geometric Scene Understanding (ECCV 2024), our workshop offers a unique focus.                        </p>
                    </div>
                </div>
            </div>
        </div>

        <div class="row mt-4">
            <div class="col-md-6">
                <div class="card border-info">
                    <div class="card-body">
                        <h5 class="card-title">EarthVision (CVPR 2021-2024)</h5>
                        <p class="card-text">
                            Focuses on satellite imagery only for large-scale environmental monitoring.
                        </p>
                    </div>
                </div>
            </div>
            <div class="col-md-6">
                <div class="card border-primary">
                    <div class="card-body">
                        <h5 class="card-title">Scalable 3D Scene Generation (ECCV 2024)</h5>
                        <p class="card-text">
                            Emphasizes large-scale 3D scene generation.
                        </p>
                    </div>
                </div>
            </div>
        </div>

        <div class="row mt-4">
            <div class="col-md-12">
                <div class="card">
                    <div class="card-body">
                        <h5 class="card-title">Our Unique Approach</h5>
                        <p class="card-text">
                            Unlike EarthVision and the ECCV 2024 workshop, our workshop explores the collaboration across multiple altitude data sources to enhance scene modeling and understanding. Specifically, we emphasize how drone-based aerial and satellite data can complement ground-level data to achieve a more complete and accurate understanding of the world and its 3D modeling.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<footer class="text-center mt-5 py-4 border-top">
    <p class="mb-1">© 2025 3D-VAST Workshop Committee</p>
    <p>Contact: <a href="mailto:shiyj2@shanghaitech.edu.cn" class="text-reset text-decoration-none">shiyj2@shanghaitech.edu.cn</a></p>
</footer>

<!-- Scripts -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.bundle.min.js"></script>
