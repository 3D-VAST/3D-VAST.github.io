<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3D-VAST: ICCV 2025 Workshop</title>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <style>
        /* 全局样式 */
        body {
            font-family: 'Segoe UI', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            padding-top: 80px;
        }

        /* 导航栏防遮挡 */
        section::before {
            display: block;
            content: " ";
            margin-top: -80px;
            height: 80px;
            visibility: hidden;
        }

        /* 专业表格样式 */
        .workshop-table {
            border-collapse: collapse;
            width: 100%;
            margin: 25px 0;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }

        .workshop-table th {
            background: #2c3e50;
            color: white;
            padding: 15px;
            text-align: left;
        }

        .workshop-table td {
            padding: 12px;
            border-bottom: 1px solid #ddd;
        }

        /* 人员卡片 */
        .profile-card {
            margin: 20px 0;
            padding: 15px;
            border-radius: 8px;
            background: #f8f9fa;
        }

        .profile-img {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            object-fit: cover;
            margin-right: 20px;
        }

        /* 章节标题 */
        .section-title {
            color: #2c3e50;
            border-left: 4px solid #3498db;
            padding-left: 15px;
            margin: 40px 0 30px;
        }
    </style>
</head>
<body>

<!-- 导航栏 -->
<nav class="navbar navbar-default navbar-fixed-top">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#mainNav">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="#">3D-VAST 2025</a>
        </div>
        <div class="collapse navbar-collapse" id="mainNav">
            <ul class="nav navbar-nav">
                <li><a href="#summary">Summary</a></li>
                <li><a href="#topic">Topic</a></li>
                <li><a href="#organizers">Organizers</a></li>
                <li><a href="#format">Format</a></li>
                <li><a href="#impacts">Impacts</a></li>
                <li><a href="#related">Related Workshops</a></li>
            </ul>
        </div>
    </div>
</nav>

<div class="container">
    <!-- Summary Section -->
    <section id="summary">
        <h2 class="section-title">1. Summary</h2>
        <table class="workshop-table">
            <tr>
                <th>Workshop Title</th>
                <td>From street to space: 3D Vision AcrossS aI<u>T</u>itudes</td>
            </tr>
            <tr>
                <th>Acronym</th>
                <td>3D-VAST</td>
            </tr>
            <tr>
                <th>Date</th>
                <td>September 29, 2025 (Half-day)</td>
            </tr>
            <tr>
                <th>Keywords</th>
                <td>Cross-altitude data fusion, aerial images, 3D scene modeling</td>
            </tr>
            <tr>
                <th>Contact</th>
                <td>Yujiao Shi &lt;shiyj2@shanghaitech.edu.cn&gt;</td>
            </tr>
        </table>
    </section>

        <!-- Topic Section -->
    <section id="topic">
        <h2 class="section-title">2. Topic</h2>

        <div class="panel panel-primary">
            <div class="panel-body">
                <!-- 背景介绍 -->
                <div class="subsection">
                    <h3>Background & Motivation</h3>
                    <p>As large-scale 3D scene modeling becomes increasingly important for applications such as urban planning, robotics, autonomous navigation, and virtual simulations, the need for diverse, high-quality visual data is greater than ever. However:</p>
                    <ul>
                        <li>Ground-level imagery faces practical limitations in accessibility and scalability</li>
                        <li>Aerial/satellite data lacks fine-grained details despite broad coverage</li>
                    </ul>
                    <p>The integration of multi-altitude data (ground, aerial, satellite) emerges as a promising solution for comprehensive 3D reconstruction.</p>
                </div>

                <!-- 核心问题 -->
                <div class="subsection" style="margin-top:30px;">
                    <h3>Core Challenges</h3>
                    <div class="challenge-list">
                        <div class="row">
                            <div class="col-md-6">
                                <ul>
                                    <li>Sparse and incomplete views</li>
                                    <li>Visual ambiguities across altitudes</li>
                                    <li>Spatio-temporal inconsistencies</li>
                                </ul>
                            </div>
                            <div class="col-md-6">
                                <ul>
                                    <li>Image quality variations</li>
                                    <li>Dynamic scene changes</li>
                                    <li>Environmental topology alterations</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                    <p>Traditional methods struggle with heterogeneous multi-altitude data, necessitating novel approaches in:</p>
                    <ul>
                        <li>Multi-scale feature alignment</li>
                        <li>Neural scene representations</li>
                        <li>Robust cross-view fusion</li>
                    </ul>
                </div>

                <!-- 研究主题 -->
                <div class="subsection" style="margin-top:30px;">
                    <h3>Research Topics</h3>
                    <div class="row">
                        <div class="col-md-6">
                            <ol start="1">
                                <li>Cross-altitude feature matching and registration</li>
                                <li>View synthesis from sparse/heterogeneous data</li>
                                <li>Sparse-view 3D reconstruction (known/unknown poses)</li>
                            </ol>
                        </div>
                        <div class="col-md-6">
                            <ol start="4">
                                <li>Generative approaches for view completion</li>
                                <li>Datasets & benchmarks for cross-altitude systems</li>
                                <li>Applications in urban planning/digital twins</li>
                            </ol>
                        </div>
                    </div>
                </div>

                <!-- 社区关联 -->
                <div class="subsection" style="margin-top:30px;">
                    <h3>Community Relevance</h3>
                    <p>This workshop addresses fundamental challenges in:</p>
                    <ul>
                        <li>3D scene modeling across scales</li>
                        <li>Multi-source data fusion</li>
                        <li>Robust multi-view geometry</li>
                    </ul>
                    <p>Key technical focuses include:</p>
                    <ul>
                        <li>Cross-altitude feature matching</li>
                        <li>Neural scene representation learning</li>
                        <li>Real-time reconstruction from heterogeneous data</li>
                    </ul>
                </div>

                <!-- 目标受众 -->
                <div class="subsection" style="margin-top:30px;">
                    <h3>Target Audience</h3>
                    <div class="audience-categories">
                        <div class="category">
                            <h4>Computer Vision Researchers</h4>
                            <ul>
                                <li>3D reconstruction specialists</li>
                                <li>Multi-view geometry experts</li>
                                <li>Data fusion researchers</li>
                            </ul>
                        </div>
                    
                        <div class="category">
                            <h4>Application Domain Experts</h4>
                            <ul>
                                <li>Robotics & autonomous navigation</li>
                                <li>Urban planning professionals</li>
                                <li>Digital twin developers</li>
                            </ul>
                        </div>
                    
                        <div class="category">
                            <h4>ML Practitioners</h4>
                            <ul>
                                <li>Neural scene representation researchers</li>
                                <li>Cross-view alignment specialists</li>
                                <li>Generative 3D modeling experts</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <style>
    .subsection {
        margin-bottom: 30px;
        padding: 15px;
        background: #f8f9fa;
        border-radius: 4px;
    }

    .subsection h3 {
        color: #2c3e50;
        border-bottom: 2px solid #3498db;
        padding-bottom: 8px;
        margin-bottom: 15px;
    }

    .challenge-list ul {
        column-count: 2;
        -webkit-column-count: 2;
        -moz-column-count: 2;
    }

    .audience-categories .category {
        margin-bottom: 20px;
        padding: 15px;
        border-left: 3px solid #3498db;
    }

    .category h4 {
        color: #34495e;
        margin-top: 0;
    }

    @media (max-width: 768px) {
        .challenge-list ul {
            column-count: 1;
            -webkit-column-count: 1;
            -moz-column-count: 1;
        }
    }
    </style>

    <!-- Organizers Section -->
    <section id="organizers">
        <h2 class="section-title">3. Organizers & Speakers</h2>
        
        <h4>Organizing Committee</h4>
        
        <!-- Yujiao Shi -->
        <div class="profile-card">
            <div class="media">       
                <div class="media-left">
                <img src="pic/organizers/Yujiao Shi.jpg" class="profile-img">
                </div>
                <div class="media-body">
                    <h4>Yujiao Shi</h4>
                    <p>Assistant Professor, ShanghaiTech University</p>
                    <p>Research: Camera localization, 3D reconstruction, view synthesis</p>
                    <p>Experience: CVPR 2023 tutorial speaker, ACM MM workshop organizer</p>
                </div>
            </div>
        </div>

         <!-- Yuanbo Xiangli -->
        <div class="profile-card">
            <div class="media">
                <!--
                <div class="media-left">
                    <img src="organizers/yuanbo_xiangli.jpg" class="profile-img">
                </div>
                -->
                <div class="media-body">
                    <h4>Yuanbo Xiangli</h4>
                    <p>Postdoctoral Researcher, Cornell University</p>
                    <p>Research: 3D city scene reconstruction with multi-source data</p>
                    <p>Experience: CVPR 2024 keynote speaker, SIGGRAPH 2024 course organizer</p>
                </div>
            </div>
        </div>

        <!-- Zuzana Kukelova -->
        <div class="profile-card">
            <div class="media">
                <!--
                <div class="media-left">
                    <img src="organizers/zuzana_kukelova.jpg" class="profile-img">
                </div>
                -->
                <div class="media-body">
                    <h4>Zuzana Kukelova</h4>
                    <p>Assistant Professor, Czech Technical University</p>
                    <p>Research: Camera geometry estimation, minimal problems in CV</p>
                    <p>Experience: 3DV 2022 General Chair, ECCV 2024 workshop organizer</p>
                </div>
            </div>
        </div>

        <!-- Bo Dai -->
        <div class="profile-card">
            <div class="media">
                <!--
                <div class="media-left">
                    <img src="organizers/bo_dai.jpg" class="profile-img">
                </div>
                -->
                <div class="media-body">
                    <h4>Bo Dai</h4>
                    <p>Assistant Professor, The University of Hong Kong</p>
                    <p>Research: Generative AI for Embodied AI and Metaverse</p>
                    <p>Experience: NeurIPS Area Chair, IET Computer Vision Associate Editor</p>
                </div>
            </div>
        </div>

        <!-- Richard Hartley -->
        <div class="profile-card">
            <div class="media">
                <!--
                <div class="media-left">
                    <img src="organizers/richard_hartley.jpg" class="profile-img">
                </div>
                -->
                <div class="media-body">
                    <h4>Richard Hartley</h4>
                    <p>Distinguished Professor Emeritus, ANU</p>
                    <p>Research: Multi-view geometry, scene reconstruction</p>
                    <p>Experience: ICCV 2013 General Chair, multi-view geometry textbook author</p>
                </div>
            </div>
        </div>

        <!-- Hongdong Li -->
        <div class="profile-card">
            <div class="media">
                <!--
                <div class="media-left">
                    <img src="organizers/hongdong_li.jpg" class="profile-img">
                </div>
                -->
                <div class="media-body">
                    <h4>Hongdong Li</h4>
                    <p>Professor, Australian National University</p>
                    <p>Research: 3D vision reconstruction, structure from motion</p>
                    <p>Experience: ACCV 2018 Program Co-Chair, Tencent Distinguished Scientist</p>
                </div>
            </div>
        </div>

         <!-- Invited Speakers -->
        <h4 style="margin-top:40px;">Invited Speakers</h4>
           <!-- Torsten Sattler -->
        <div class="profile-card">
            <div class="media">
                <!--
                <div class="media-left">
                    <img src="speakers/torsten_sattler.jpg" class="profile-img">
                </div>
                -->
                <div class="media-body">
                    <h4>Torsten Sattler</h4>
                    <p>Senior Researcher, Czech Technical University</p>
                    <p>Expertise: Robust 3D reconstruction and visual localization</p>
                    <p>Experience: Program Chair for DAGM GCPR'20, 3DV'22 General Chair</p>
                </div>
            </div>
        </div>

        <!-- Angela Dai -->
        <div class="profile-card">
            <div class="media">
                <!--
                <div class="media-left">
                    <img src="speakers/angela_dai.jpg" class="profile-img">
                </div>
                -->
                <div class="media-body">
                    <h4>Angela Dai</h4>
                    <p>Associate Professor, Technical University of Munich</p>
                    <p>Expertise: 3D scene understanding and modeling</p>
                    <p>Awards: ERC Starting Grant, Eurographics Young Researcher Award</p>
                </div>
            </div>
        </div>

        <!-- Noah Snavely -->
        <div class="profile-card">
            <div class="media">
                <!--
                <div class="media-left">
                    <img src="speakers/noah_snavely.jpg" class="profile-img">
                </div>
                -->
                <div class="media-body">
                    <h4>Noah Snavely</h4>
                    <p>Professor, Cornell Tech & Google DeepMind</p>
                    <p>Expertise: 3D scene understanding from images</p>
                    <p>Awards: Sloan Fellowship, SIGGRAPH Significant New Researcher Award</p>
                </div>
            </div>
        </div>

        <!-- Nathan Jacobs -->
        <div class="profile-card">
            <div class="media">
                <!--
                <div class="media-left">
                    <img src="speakers/nathan_jacobs.jpg" class="profile-img">
                </div>
                -->
                <div class="media-body">
                    <h4>Nathan Jacobs</h4>
                    <p>Professor, Washington University in St. Louis</p>
                    <p>Expertise: Geospatial analysis from crowdsourced imagery</p>
                    <p>Funding: NSF, NIH, DARPA, IARPA, etc.</p>
                </div>
            </div>
        </div>

        <!-- Jingyi Yu -->
        <div class="profile-card">
            <div class="media">
                <!--
                <div class="media-left">
                    <img src="speakers/jingyi_yu.jpg" class="profile-img">
                </div>
                -->
                <div class="media-body">
                    <h4>Jingyi Yu</h4>
                    <p>Chair Professor, ShanghaiTech University</p>
                    <p>Expertise: Computational photography and camera design</p>
                    <p>Awards: NSF CAREER Award, AFOSR YIP Award</p>
                </div>
            </div>
        </div>

        
    </section>

    <!-- Format Section -->
    <section id="format">
        <h2 class="section-title">4. Format & Logistics</h2>
        
        <h4>Schedule</h4>
        <table class="workshop-table">
            <tr>
                <th>Time</th>
                <th>Session</th>
            </tr>
            <tr>
                <td>08:30-08:35</td>
                <td>Opening Remarks</td>
            </tr>
            <tr>
                <td>08:35-09:05</td>
                <td>Keynote Speech 1</td>
            </tr>
            <!-- 完整日程 -->
        </table>

        <h4>Paper Submission</h4>
        <ul>
            <li>Submission Deadline: May 20, 2024</li>
            <li>Notification: June 20, 2024</li>
            <li>Camera Ready: July 20, 2024</li>
        </ul>
    </section>

    <!-- Impacts Section -->
    <section id="impacts">
        <h2 class="section-title">5. Broader Impacts</h2>
        <div class="panel panel-default">
            <div class="panel-body">
                <h4>Applications</h4>
                <ul>
                    <li>Urban planning and smart cities</li>
                    <li>Autonomous navigation systems</li>
                    <li>Digital twin development</li>
                </ul>

                <h4>Ethical Considerations</h4>
                <ul>
                    <li>Privacy protection in multi-altitude data</li>
                    <li>Algorithmic bias mitigation</li>
                    <li>Surveillance ethics</li>
                </ul>
            </div>
        </div>
    </section>

    <!-- Related Workshops Section -->
    <section id="related">
        <h2 class="section-title">6. Related Workshops</h2>
        <table class="workshop-table">
            <tr>
                <th>Workshop</th>
                <th>Comparison</th>
            </tr>
            <tr>
                <td>EarthVision (CVPR)</td>
                <td>Focuses on satellite imagery only</td>
            </tr>
            <tr>
                <td>ECCV 2024 Workshop</td>
                <td>Emphasizes large-scale generation</td>
            </tr>
        </table>
    </section>

    <footer class="text-center" style="margin: 50px 0;">
        <p>© 2025 3D-VAST Workshop Committee</p>
        <p>Contact: <a href="mailto:shiyj2@shanghaitech.edu.cn">shiyj2@shanghaitech.edu.cn</a></p>
    </footer>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
</body>
</html>
